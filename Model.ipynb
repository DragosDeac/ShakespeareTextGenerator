{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy google.colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epCsdRkayxBZ",
        "outputId": "6e5c0b21-50d7-4e5c-8a49-f4358b535eea"
      },
      "id": "epCsdRkayxBZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: google.colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.10/dist-packages (from google.colab) (2.27.0)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google.colab) (5.5.6)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.10/dist-packages (from google.colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google.colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.10/dist-packages (from google.colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (from google.colab) (2.2.2)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google.colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.10/dist-packages (from google.colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.3.3 in /usr/local/lib/python3.10/dist-packages (from google.colab) (6.3.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google.colab) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google.colab) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google.colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google.colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google.colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google.colab) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google.colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google.colab) (0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google.colab) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google.colab) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google.colab) (24.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google.colab) (4.67.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google.colab)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google.colab) (4.9.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (7.16.5)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google.colab) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->google.colab) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->google.colab) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google.colab) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google.colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google.colab) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google.colab) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google.colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google.colab) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google.colab) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google.colab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google.colab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google.colab) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google.colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google.colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google.colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.27.0->google.colab) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google.colab) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->google.colab) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google.colab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google.colab) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google.colab) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google.colab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google.colab) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google.colab) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google.colab) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google.colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google.colab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google.colab) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google.colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google.colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google.colab) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google.colab) (1.2.2)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5JFmbKxyxNV"
      },
      "id": "n5JFmbKxyxNV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mT3Ng-_E_fqL"
      },
      "id": "mT3Ng-_E_fqL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRUBeR3L_glZ"
      },
      "id": "oRUBeR3L_glZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "\n",
        "# gpu available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise RuntimeError(\"GPU is not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIonlFGk0Oup",
        "outputId": "71c4106b-fe60-468c-837b-bfce1f6bbda4"
      },
      "id": "KIonlFGk0Oup",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters:\n",
        "batch_size = 16  # Number of independent sequences processed in parallel\n",
        "block_size = 128  # Maximum context length for predictions\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 488\n",
        "n_head = 7\n",
        "n_layer = 6\n",
        "dropout = 0.1\n",
        "train = 0.9\n",
        "#torch.manual_seed(1337) #Doing seeded tests for the sake of testing"
      ],
      "metadata": {
        "id": "LwNznXfx0S7v"
      },
      "id": "LwNznXfx0S7v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/alllines.txt'\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    print(\"Length of dataset in characters is:\", len(text))\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Error: File missing {file_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Error {e}\")"
      ],
      "metadata": {
        "id": "SE5msODf0gCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679961b6-4c2e-4dc8-89c7-d163e8d8e3a7"
      },
      "id": "SE5msODf0gCJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters is: 4583798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Character mappings\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "RHoxceCC-q_F"
      },
      "id": "RHoxceCC-q_F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(train * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "df9J4QyX-5-c"
      },
      "id": "df9J4QyX-5-c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)  # pray data is moved to T4\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "pbmqq4iU_C3_"
      },
      "id": "pbmqq4iU_C3_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classes:\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "WlegAOW5_Jw6"
      },
      "id": "WlegAOW5_Jw6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom LayerNorm normalizes input by mean and standard deviation, then scales and shifts with learnable parameters - I know that\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, n_embd, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(n_embd))\n",
        "        self.beta = nn.Parameter(torch.zeros(n_embd))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "\n",
        "        normalized = (x-mean)/torch.sqrt(std+self.eps) #standard deviation is already the square root of the varianec but using the sqrt gives better restults. I don't know why but it works ish\n",
        "        return self.gamma * normalized + self.beta\n"
      ],
      "metadata": {
        "id": "6cdvzW6d_OSN"
      },
      "id": "6cdvzW6d_OSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model components - a single attention head performing scaled dot-product attention with masking, dropout, and learned Query/Key/Value projections\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        sq_n_embd = np.sqrt(1 / n_embd)\n",
        "        self.W_q = nn.Parameter(torch.rand(n_embd, head_size) * 2 * sq_n_embd - sq_n_embd)\n",
        "        self.W_k = nn.Parameter(torch.rand(n_embd, head_size) * 2 * sq_n_embd - sq_n_embd)\n",
        "        self.W_v = nn.Parameter(torch.rand(n_embd, head_size) * 2 * sq_n_embd - sq_n_embd)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = torch.matmul(x, self.W_k)\n",
        "        q = torch.matmul(x, self.W_q)\n",
        "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = torch.matmul(x, self.W_v)\n",
        "        out = wei @ v\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "hLsdkv_H_Tdw"
      },
      "id": "hLsdkv_H_Tdw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implement multi-head attention by combining outputs from multiple atention heads and projecting them into the model's embedding space\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "JF4Og0za_jN7"
      },
      "id": "JF4Og0za_jN7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# two-layer feedforward network with ReLU activation\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "2PBHQpwI_kMf"
      },
      "id": "2PBHQpwI_kMf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performs attention (ln1), adds output, applies feedforward (ln2), adds result - basic transformer block\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = LayerNorm(n_embd)\n",
        "        self.ln2 = LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "QybdKHkWAmoa"
      },
      "id": "QybdKHkWAmoa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maps token and position embeddings through transformer blocks, applies layer normalization,\n",
        "# predicts logits via a linear head, optimizes with cross-entropy, and generates text iteratively using autoregressive decoding\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Parameter(torch.zeros(block_size, n_embd))\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table[:T, :]\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            return logits, None\n",
        "        else:\n",
        "            logits = logits.view(B * T, -1)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "hcE5J08VcCds"
      },
      "id": "hcE5J08VcCds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = GPTLanguageModel().to(device)\n",
        "\n",
        "# GPU usage\n",
        "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
        "print(f\"Number of model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M parameters\")\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Track perplexity\n",
        "train_perplexity = []\n",
        "val_perplexity = []\n",
        "\n",
        "# Training loop with perplexity\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        train_loss = losses['train']\n",
        "        val_loss = losses['val']\n",
        "        train_perplexity = torch.exp(torch.tensor(train_loss)).item()\n",
        "        val_perplexity = torch.exp(torch.tensor(val_loss)).item()\n",
        "        print(f\"Step {iter}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}, Val Perplexity: {val_perplexity:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Generate text\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mYDUL_xcZ1C",
        "outputId": "9143cdb9-e0aa-4984-a525-a174b0038277"
      },
      "id": "7mYDUL_xcZ1C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on device: cuda:0\n",
            "Number of model parameters: 17.26M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-a409509d65b2>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_perplexity = torch.exp(torch.tensor(train_loss)).item()\n",
            "<ipython-input-21-a409509d65b2>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_perplexity = torch.exp(torch.tensor(val_loss)).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: Train Loss 4.4381, Val Loss 4.4410, Val Perplexity: 84.8602\n",
            "Step 100: Train Loss 2.3746, Val Loss 2.3825, Val Perplexity: 10.8315\n",
            "Step 200: Train Loss 2.3260, Val Loss 2.3298, Val Perplexity: 10.2759\n",
            "Step 300: Train Loss 2.3099, Val Loss 2.3186, Val Perplexity: 10.1617\n",
            "Step 400: Train Loss 2.2806, Val Loss 2.2876, Val Perplexity: 9.8511\n",
            "Step 500: Train Loss 2.2236, Val Loss 2.2300, Val Perplexity: 9.2994\n",
            "Step 600: Train Loss 2.0867, Val Loss 2.0887, Val Perplexity: 8.0741\n",
            "Step 700: Train Loss 1.9671, Val Loss 1.9717, Val Perplexity: 7.1825\n",
            "Step 800: Train Loss 1.8855, Val Loss 1.8904, Val Perplexity: 6.6221\n",
            "Step 900: Train Loss 1.8308, Val Loss 1.8366, Val Perplexity: 6.2749\n",
            "Step 1000: Train Loss 1.7850, Val Loss 1.7877, Val Perplexity: 5.9757\n",
            "Step 1100: Train Loss 1.7423, Val Loss 1.7463, Val Perplexity: 5.7335\n",
            "Step 1200: Train Loss 1.7125, Val Loss 1.7190, Val Perplexity: 5.5787\n",
            "Step 1300: Train Loss 1.6798, Val Loss 1.6883, Val Perplexity: 5.4102\n",
            "Step 1400: Train Loss 1.6619, Val Loss 1.6671, Val Perplexity: 5.2969\n",
            "Step 1500: Train Loss 1.6331, Val Loss 1.6481, Val Perplexity: 5.1971\n",
            "Step 1600: Train Loss 1.6169, Val Loss 1.6349, Val Perplexity: 5.1288\n",
            "Step 1700: Train Loss 1.5995, Val Loss 1.6122, Val Perplexity: 5.0138\n",
            "Step 1800: Train Loss 1.5852, Val Loss 1.5995, Val Perplexity: 4.9508\n",
            "Step 1900: Train Loss 1.5733, Val Loss 1.5879, Val Perplexity: 4.8933\n",
            "Step 2000: Train Loss 1.5612, Val Loss 1.5753, Val Perplexity: 4.8324\n",
            "Step 2100: Train Loss 1.5474, Val Loss 1.5676, Val Perplexity: 4.7949\n",
            "Step 2200: Train Loss 1.5357, Val Loss 1.5577, Val Perplexity: 4.7481\n",
            "Step 2300: Train Loss 1.5264, Val Loss 1.5510, Val Perplexity: 4.7163\n",
            "Step 2400: Train Loss 1.5010, Val Loss 1.5380, Val Perplexity: 4.6553\n",
            "Step 2500: Train Loss 1.5057, Val Loss 1.5258, Val Perplexity: 4.5986\n",
            "Step 2600: Train Loss 1.5028, Val Loss 1.5277, Val Perplexity: 4.6075\n",
            "Step 2700: Train Loss 1.4851, Val Loss 1.5155, Val Perplexity: 4.5519\n",
            "Step 2800: Train Loss 1.4831, Val Loss 1.5075, Val Perplexity: 4.5155\n",
            "Step 2900: Train Loss 1.4734, Val Loss 1.5050, Val Perplexity: 4.5042\n",
            "Step 3000: Train Loss 1.4658, Val Loss 1.4990, Val Perplexity: 4.4772\n",
            "Step 3100: Train Loss 1.4575, Val Loss 1.4930, Val Perplexity: 4.4506\n",
            "Step 3200: Train Loss 1.4572, Val Loss 1.4906, Val Perplexity: 4.4396\n",
            "Step 3300: Train Loss 1.4408, Val Loss 1.4822, Val Perplexity: 4.4026\n",
            "Step 3400: Train Loss 1.4419, Val Loss 1.4728, Val Perplexity: 4.3616\n",
            "Step 3500: Train Loss 1.4365, Val Loss 1.4706, Val Perplexity: 4.3518\n",
            "Step 3600: Train Loss 1.4347, Val Loss 1.4639, Val Perplexity: 4.3226\n",
            "Step 3700: Train Loss 1.4172, Val Loss 1.4608, Val Perplexity: 4.3092\n",
            "Step 3800: Train Loss 1.4208, Val Loss 1.4591, Val Perplexity: 4.3021\n",
            "Step 3900: Train Loss 1.4089, Val Loss 1.4592, Val Perplexity: 4.3027\n",
            "Step 4000: Train Loss 1.4118, Val Loss 1.4528, Val Perplexity: 4.2752\n",
            "Step 4100: Train Loss 1.4081, Val Loss 1.4596, Val Perplexity: 4.3044\n",
            "Step 4200: Train Loss 1.4063, Val Loss 1.4423, Val Perplexity: 4.2305\n",
            "Step 4300: Train Loss 1.4047, Val Loss 1.4400, Val Perplexity: 4.2208\n",
            "Step 4400: Train Loss 1.3990, Val Loss 1.4412, Val Perplexity: 4.2258\n",
            "Step 4500: Train Loss 1.4000, Val Loss 1.4387, Val Perplexity: 4.2151\n",
            "Step 4600: Train Loss 1.3916, Val Loss 1.4322, Val Perplexity: 4.1880\n",
            "Step 4700: Train Loss 1.3879, Val Loss 1.4253, Val Perplexity: 4.1591\n",
            "Step 4800: Train Loss 1.3837, Val Loss 1.4243, Val Perplexity: 4.1550\n",
            "Step 4900: Train Loss 1.3735, Val Loss 1.4263, Val Perplexity: 4.1634\n",
            "Step 4999: Train Loss 1.3813, Val Loss 1.4281, Val Perplexity: 4.1709\n",
            "\tclaimbinem. Royals! Bringhas so be you,\"\n",
            "\"trrain what jest, and day a des in the beguns to ushan a gall distake us,\"\n",
            "\"for the roped of much an old Watester mustry the train's lift urgh,\"\n",
            "\"Light deed in my make all yourself: lived you,\"\n",
            "\"nescies. God these strange may there, by tweeth gen,\"\n",
            "\"Ride they come yet.\"\n",
            "\"You have fortune heart, procise me Nought wool,\"\n",
            "\"I to your back the meltingers palments:\"\n",
            "\"Lives wi from it bear with the people burneds, togething the\"\n",
            "\"tirest your knave very Docteath\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sLaPYPYS_i5g"
      },
      "id": "sLaPYPYS_i5g"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWnOLcWgBLtt",
        "outputId": "7514a528-cf37-4498-d02d-1c85aa2d07d1"
      },
      "id": "gWnOLcWgBLtt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 12 12:18:53 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0              69W /  70W |   1011MiB / 15360MiB |     73%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}